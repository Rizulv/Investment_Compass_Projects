{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53dc2710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date        Open        High         Low       Close   Adj Close  \\\n",
      "0  2018-01-01  430.950012  436.399994  422.250000  424.450012  423.131256   \n",
      "1  2018-01-02  428.850006  440.850006  422.000000  439.299988  437.935089   \n",
      "2  2018-01-03  440.399994  441.399994  431.950012  433.899994  432.551849   \n",
      "3  2018-01-04  430.000000  433.299988  425.750000  429.950012  428.614166   \n",
      "4  2018-01-05  431.250000  436.350006  429.799988  431.600006  430.259033   \n",
      "\n",
      "     Volume  \n",
      "0   6807536  \n",
      "1  15331261  \n",
      "2   9794953  \n",
      "3   8395377  \n",
      "4   7021611  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\A\\Desktop\\The Investment Compass\\TATAMOTORS.NS.csv'\n",
    "tata_motors_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(tata_motors_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b83f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'Date' column to datetime format\n",
    "tata_motors_data['Date'] = pd.to_datetime(tata_motors_data['Date'])\n",
    "\n",
    "# Set the 'Date' column as the index\n",
    "tata_motors_data.set_index('Date', inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "print(tata_motors_data.isnull().sum())\n",
    "\n",
    "# Fill missing values if any\n",
    "tata_motors_data.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ac008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target variable\n",
    "features = ['Open', 'High', 'Low', 'Volume']\n",
    "target = 'Close'\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(tata_motors_data) * 0.8)\n",
    "train_data = tata_motors_data.iloc[:train_size]\n",
    "test_data = tata_motors_data.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c729852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 4s 93ms/step - loss: 0.0607\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 0.0097\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 0.0041\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 0.0023\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.0020\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 1s 83ms/step - loss: 0.0018\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 0.0017\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 0.0017\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 0.0016\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 1s 93ms/step - loss: 0.0015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd19a1a2e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_train_data = scaler.fit_transform(train_data)\n",
    "\n",
    "# Prepare the data for LSTM\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        X.append(data[i:(i+time_step), 0])\n",
    "        y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "time_step = 100\n",
    "X_train, y_train = create_dataset(scaled_train_data, time_step)\n",
    "\n",
    "# Reshape input to be [samples, time steps, features]\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8aa81b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 19ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (147,1) doesn't match the broadcast shape (147,6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23824\\1740758094.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    527\u001b[0m         )\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (147,1) doesn't match the broadcast shape (147,6)"
     ]
    }
   ],
   "source": [
    "# Prepare the test data\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "X_test, y_test = create_dataset(scaled_test_data, time_step)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f'Root Mean Squared Error: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eed6db8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 19ms/step\n",
      "Root Mean Squared Error: 434.1021762812477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Normalize only the closing prices\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_train_data = scaler.fit_transform(train_data[target].values.reshape(-1, 1))\n",
    "\n",
    "# Modify the create_dataset function to work with 1D arrays\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_step - 1):\n",
    "        X.append(data[i:(i + time_step), 0])\n",
    "        y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare the data for LSTM\n",
    "time_step = 100\n",
    "X_train, y_train = create_dataset(scaled_train_data, time_step)\n",
    "\n",
    "# Reshape input to be [samples, time steps, features]\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "\n",
    "# Train the model (same as before)\n",
    "\n",
    "# Prepare the test data\n",
    "scaled_test_data = scaler.transform(test_data[target].values.reshape(-1, 1))\n",
    "X_test, y_test = create_dataset(scaled_test_data, time_step)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f'Root Mean Squared Error: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b167df21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Predictions for the next 3 days: [477.94522 478.39774 478.98425]\n"
     ]
    }
   ],
   "source": [
    "# Assume you have the most recent 100 days of data for input\n",
    "recent_data = scaled_train_data[-100:]\n",
    "recent_data = recent_data.reshape(1, recent_data.shape[0], 1)\n",
    "\n",
    "# Generate predictions for the next 3 days\n",
    "next_3_days_predictions = []\n",
    "for _ in range(3):\n",
    "    # Predict the next day's price\n",
    "    next_day_pred = model.predict(recent_data)\n",
    "    next_3_days_predictions.append(next_day_pred[0][0])\n",
    "    \n",
    "    # Update recent_data to include the predicted value and remove the oldest value\n",
    "    recent_data = np.append(recent_data[:, 1:, :], next_day_pred.reshape(1, 1, 1), axis=1)\n",
    "\n",
    "# Inverse transform the predictions to get the actual price values\n",
    "next_3_days_predictions = scaler.inverse_transform(np.array(next_3_days_predictions).reshape(-1, 1))\n",
    "print(\"Predictions for the next 3 days:\", next_3_days_predictions.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8ecd47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
